# -*- coding: utf-8 -*-
"""
Created on Mon Mar 09 22:30:12 2015

@author: Greg
"""
import ConfigParser
import numpy as np
import theano

class Network():
    
    def __init__(self,parameters_file):
        config = ConfigParser.ConfigParser()
        config.read(parameters_file)
        rng = np.random.RandomState(0)
        self.num_iterations = 50
        
        """
        Load network Parameters from config file
        """
        
        self.batch_size = config.getint("Parameters",'batch_size')
        self.num_trials = config.getint("Parameters",'num_trials')
        self.reduced_learning_rate = config.getfloat("Parameters",'reduced_learning_rate')
        self.N = config.getint("NeuronParameters",'N')
        self.OC = config.getint("NeuronParameters",'OC')
        self.p = config.getfloat("NeuronParameters",'p')
        self.alpha = config.getfloat("LearningRates",'alpha')
        self.beta = config.getfloat("LearningRates",'beta')
        self.gamma = config.getfloat("LearningRates",'gamma')
        self.eta_ave = config.getfloat("LearningRates",'eta_ave')
        self.lateral_constraint = config.getfloat('LearningRates','lateral_constraint')
        
        """
        Initialize X, W, Q, and theta; the input and network parameters.
        """        
        
        self.M = self.OC*self.N        
        self.Q = rng.randn(self.N,self.M)
        self.Q = self.Q.dot(np.diag(1./np.sqrt(np.diag(self.Q.T.dot(self.Q)))))
        self.W = np.zeros((self.M,self.M))
        self.theta = 2.*np.ones(self.M)
        self.X = np.zeros((self.batch_size,self.N))
        
        """
        These are used for the activities function
        """
        
        self.Y = np.zeros((self.batch_size,self.M))
        self.spike_train=np.zeros((self.batch_size,self.M,self.num_iterations))
        
        """
        The following are used for analyzing, plotting, and storing the data
        generated by our neural network.
        """
        self.Y_ave = self.p
        self.Cyy_ave = self.p**2
        
        self.muy = np.mean(self.Y,axis=0)
        self.Cyy = self.Y.T.dot(self.Y)/self.batch_size
        
        
        self.Cyy_ave_pertrial=np.zeros(self.num_trials)
        self.Y_ave_pertrial=np.zeros_like(self.Cyy_ave_pertrial)   
        
        #mag_dW will track the magnitude changes in dW

        self.mag_dW=np.zeros(self.num_trials)
        
        #mag_W will track the magnitude in W
        
        self.mag_W = np.zeros_like(self.mag_dW)
        
        self.reconstruction_error=np.zeros_like(self.mag_dW)
        
        
        
    def ReduceLearning(self,tt):
        
        if tt >= 5000:
            self.gamma=self.gamma*self.reduced_learning_rate
            self.alpha=self.alpha*self.reduced_learning_rate
            self.beta=self.beta*self.reduced_learning_rate
            
    def UpdateData(self,tt,learn):
        self.mag_dW[tt]=np.sqrt(np.sum(np.sqr(learn.dW)))
        self.mag_W[tt] =np.sqrt(np.sum(np.sqr(self.W))) 
        
        self.muy = np.mean(self.Y,axis=0)
        self.Cyy = self.Y.T.dot(self.Y)/self.batch_size
        
        self.reconstruction_error[tt]=np.sum(np.sum((self.X-self.Y.dot(self.Q.T))**2))/(2*self.N*self.batch_size)  
        self.Y_ave = (1.-self.eta_ave)*self.Y_ave + self.eta_ave*self.muy
        self.Cyy_ave=(1.-self.eta_ave)*self.Cyy_ave + self.eta_ave*self.Cyy
        self.Cyy_ave_pertrial[tt]=sum(sum(self.Cyy-np.diag(np.diag(self.Cyy))))/(self.N**2-self.N)
        self.Y_ave_pertrial[tt]=np.mean(self.Y_ave)
        
        """
        We shall determine the correlation between dW and stdp by dW*stdp/(|dW||stdp|)
        Due to coding changes, we will no longer be calculating both SAILNet learning
        rule and the newer form of STDP
        """
        #cor_dW_stdp[tt]=sum(sum(dW.dot(stdp)))/(np.linalg.norm(dW)*np.linalg.norm(stdp))
    
class Network_gpu():
    
    def __init__(self,parameters_file):
        config = ConfigParser.ConfigParser()
        config.read(parameters_file)
        rng = np.random.RandomState(0)
        self.num_iterations = 50
        
        """
        Load network Parameters from config file
        """
        
        self.batch_size = config.getint("Parameters",'batch_size')
        self.num_trials = config.getint("Parameters",'num_trials')
        self.reduced_learning_rate = config.getfloat("Parameters",'reduced_learning_rate')
        self.N = config.getint("NeuronParameters",'N')
        self.OC = config.getint("NeuronParameters",'OC')
        self.p = config.getfloat("NeuronParameters",'p')
        self.alpha = theano.shared(np.array(config.getfloat("LearningRates",'alpha')).astype('float32'))
        self.beta = theano.shared(np.array(config.getfloat("LearningRates",'beta')).astype('float32'))
        self.gamma = theano.shared(np.array(config.getfloat("LearningRates",'gamma')).astype('float32'))
        self.eta_ave = config.getfloat("LearningRates",'eta_ave')
        self.lateral_constraint = config.getfloat('LearningRates','lateral_constraint')
        
        """
        Initialize X, W, Q, and theta; the input and network parameters.
        """        
        
        self.M = self.OC*self.N        
        self.Q = rng.randn(self.N,self.M)
        self.Q = theano.shared(self.Q.dot(np.diag(1./np.sqrt(np.diag(self.Q.T.dot(self.Q))))).astype('float32'))
        self.W = theano.shared(np.zeros((self.M,self.M)).astype('float32'))
        self.theta = theano.shared(2.*np.ones(self.M).astype('float32'))
        self.X = theano.shared(np.zeros((self.batch_size,self.N)).astype('float32'))
        
        """
        These are used for the activities function
        """
        
        self.Y = theano.shared(np.zeros((self.batch_size,self.M)).astype('float32'))
        self.spike_train = theano.shared(np.zeros((self.batch_size,
                                                   self.M,
                                                   self.num_iterations)).astype('float32'))
        
    def to_cpu(self):
        items = self.__dict__
        updates = {}
        print self.__dict__
        for key, value in items.iteritems():
            if isinstance(value, theano.tensor.sharedvar.SharedVariable):
                updates[key] = value.get_value()
        self.__dict__.update(updates)
